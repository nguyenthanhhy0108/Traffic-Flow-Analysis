{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from video_tracking import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "Model summary: 604 layers, 50880768 parameters, 0 gradients, 237.6 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "video_tracking = video_tracking()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_img_path = sorted(os.listdir(\"C:\\\\Users\\\\ADMIN\\\\OneDrive\\\\Desktop\\\\images\"), key=lambda x: int(re.search(r'\\d+', x).group()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Computer_Vision_(CS231)\\Analysis_traffic\\traffic_flow_analysis_with_yolov9\\safety_helmet_people\\48shard_hat_workers9.jpg\n",
      "D:\\Computer_Vision_(CS231)\\Analysis_traffic\\traffic_flow_analysis_with_yolov9\\safety_helmet_people\\52shard_hat_workers9.jpg\n",
      "D:\\Computer_Vision_(CS231)\\Analysis_traffic\\traffic_flow_analysis_with_yolov9\\safety_helmet_people\\48shard_hat_workers83.jpg\n",
      "D:\\Computer_Vision_(CS231)\\Analysis_traffic\\traffic_flow_analysis_with_yolov9\\safety_helmet_people\\48shard_hat_workers85.jpg\n",
      "D:\\Computer_Vision_(CS231)\\Analysis_traffic\\traffic_flow_analysis_with_yolov9\\safety_helmet_people\\53shard_hat_workers85.jpg\n",
      "D:\\Computer_Vision_(CS231)\\Analysis_traffic\\traffic_flow_analysis_with_yolov9\\safety_helmet_people\\54shard_hat_workers85.jpg\n",
      "D:\\Computer_Vision_(CS231)\\Analysis_traffic\\traffic_flow_analysis_with_yolov9\\safety_helmet_people\\55shard_hat_workers85.jpg\n",
      "D:\\Computer_Vision_(CS231)\\Analysis_traffic\\traffic_flow_analysis_with_yolov9\\safety_helmet_people\\54shard_hat_workers87.jpg\n",
      "D:\\Computer_Vision_(CS231)\\Analysis_traffic\\traffic_flow_analysis_with_yolov9\\safety_helmet_people\\56shard_hat_workers87.jpg\n",
      "D:\\Computer_Vision_(CS231)\\Analysis_traffic\\traffic_flow_analysis_with_yolov9\\safety_helmet_people\\56shard_hat_workers88.jpg\n",
      "D:\\Computer_Vision_(CS231)\\Analysis_traffic\\traffic_flow_analysis_with_yolov9\\safety_helmet_people\\56shard_hat_workers94.jpg\n",
      "D:\\Computer_Vision_(CS231)\\Analysis_traffic\\traffic_flow_analysis_with_yolov9\\safety_helmet_people\\56shard_hat_workers95.jpg\n",
      "D:\\Computer_Vision_(CS231)\\Analysis_traffic\\traffic_flow_analysis_with_yolov9\\safety_helmet_people\\57shard_hat_workers95.jpg\n",
      "D:\\Computer_Vision_(CS231)\\Analysis_traffic\\traffic_flow_analysis_with_yolov9\\safety_helmet_people\\56shard_hat_workers99.jpg\n",
      "D:\\Computer_Vision_(CS231)\\Analysis_traffic\\traffic_flow_analysis_with_yolov9\\safety_helmet_people\\58shard_hat_workers99.jpg\n",
      "D:\\Computer_Vision_(CS231)\\Analysis_traffic\\traffic_flow_analysis_with_yolov9\\safety_helmet_people\\59shard_hat_workers99.jpg\n",
      "D:\\Computer_Vision_(CS231)\\Analysis_traffic\\traffic_flow_analysis_with_yolov9\\safety_helmet_people\\56shard_hat_workers838.jpg\n",
      "D:\\Computer_Vision_(CS231)\\Analysis_traffic\\traffic_flow_analysis_with_yolov9\\safety_helmet_people\\58shard_hat_workers838.jpg\n",
      "D:\\Computer_Vision_(CS231)\\Analysis_traffic\\traffic_flow_analysis_with_yolov9\\safety_helmet_people\\56shard_hat_workers844.jpg\n",
      "D:\\Computer_Vision_(CS231)\\Analysis_traffic\\traffic_flow_analysis_with_yolov9\\safety_helmet_people\\60shard_hat_workers844.jpg\n",
      "D:\\Computer_Vision_(CS231)\\Analysis_traffic\\traffic_flow_analysis_with_yolov9\\safety_helmet_people\\61shard_hat_workers844.jpg\n",
      "D:\\Computer_Vision_(CS231)\\Analysis_traffic\\traffic_flow_analysis_with_yolov9\\safety_helmet_people\\62shard_hat_workers844.jpg\n",
      "D:\\Computer_Vision_(CS231)\\Analysis_traffic\\traffic_flow_analysis_with_yolov9\\safety_helmet_people\\56shard_hat_workers845.jpg\n",
      "D:\\Computer_Vision_(CS231)\\Analysis_traffic\\traffic_flow_analysis_with_yolov9\\safety_helmet_people\\63shard_hat_workers845.jpg\n",
      "D:\\Computer_Vision_(CS231)\\Analysis_traffic\\traffic_flow_analysis_with_yolov9\\safety_helmet_people\\64shard_hat_workers845.jpg\n",
      "D:\\Computer_Vision_(CS231)\\Analysis_traffic\\traffic_flow_analysis_with_yolov9\\safety_helmet_people\\65shard_hat_workers845.jpg\n",
      "D:\\Computer_Vision_(CS231)\\Analysis_traffic\\traffic_flow_analysis_with_yolov9\\safety_helmet_people\\65shard_hat_workers848.jpg\n",
      "D:\\Computer_Vision_(CS231)\\Analysis_traffic\\traffic_flow_analysis_with_yolov9\\safety_helmet_people\\65shard_hat_workers850.jpg\n",
      "D:\\Computer_Vision_(CS231)\\Analysis_traffic\\traffic_flow_analysis_with_yolov9\\safety_helmet_people\\65shard_hat_workers852.jpg\n",
      "D:\\Computer_Vision_(CS231)\\Analysis_traffic\\traffic_flow_analysis_with_yolov9\\safety_helmet_people\\66shard_hat_workers852.jpg\n",
      "D:\\Computer_Vision_(CS231)\\Analysis_traffic\\traffic_flow_analysis_with_yolov9\\safety_helmet_people\\67shard_hat_workers852.jpg\n",
      "D:\\Computer_Vision_(CS231)\\Analysis_traffic\\traffic_flow_analysis_with_yolov9\\safety_helmet_people\\65shard_hat_workers853.jpg\n",
      "D:\\Computer_Vision_(CS231)\\Analysis_traffic\\traffic_flow_analysis_with_yolov9\\safety_helmet_people\\68shard_hat_workers853.jpg\n"
     ]
    }
   ],
   "source": [
    "for img_path in lst_img_path:\n",
    "    video_tracking.tracking_on_image(\n",
    "        os.path.join(\"C:\\\\Users\\\\ADMIN\\\\OneDrive\\\\Desktop\\\\images\", img_path), \n",
    "        \"D:\\\\Computer_Vision_(CS231)\\\\Analysis_traffic\\\\traffic_flow_analysis_with_yolov9\\\\safety_helmet_people\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(\"D:\\\\Computer_Vision_(CS231)\\\\Analysis_traffic\\\\traffic_flow_analysis_with_yolov9\\\\safety_helmet_people\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAFETY HELMET 0\n",
    "# STANDARD HELMET 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_0 = sorted(os.listdir(\"D:\\\\Computer_Vision_(CS231)\\\\Analysis_traffic\\\\traffic_flow_analysis_with_yolov9\\\\safety_helmet_people\"), key=lambda x: int(re.search(r'\\d+', x).group()))\n",
    "\n",
    "lst_1 = sorted(os.listdir(\"C:\\\\Users\\\\ADMIN\\\\OneDrive\\\\Desktop\\\\helmet\\\\train\\\\1\"), key=lambda x: int(re.search(r'\\d+', x).group()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_img_0 = []\n",
    "\n",
    "common_size = (240, 240)  # Set the desired width and height\n",
    "\n",
    "for path in lst_0:\n",
    "    img_path = os.path.join(\"D:\\\\Computer_Vision_(CS231)\\\\Analysis_traffic\\\\traffic_flow_analysis_with_yolov9\\\\safety_helmet_people\", path)\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        continue\n",
    "    resized_img = cv2.resize(img, common_size)\n",
    "    normalized_img = resized_img / 255.0\n",
    "    lst_img_0.append(normalized_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_img_1 = []\n",
    "\n",
    "common_size = (240, 240)  # Set the desired width and height\n",
    "\n",
    "for path in lst_1:\n",
    "    img_path = os.path.join(\"C:\\\\Users\\\\ADMIN\\\\OneDrive\\\\Desktop\\\\helmet\\\\train\\\\1\", path)\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        continue\n",
    "    resized_img = cv2.resize(img, common_size)\n",
    "    normalized_img = resized_img / 255.0\n",
    "    lst_img_1.append(normalized_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "label_0 = np.zeros(len(lst_img_0)).tolist()\n",
    "label_1 = np.ones(len(lst_img_1)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_img = lst_img_0 + lst_img_1\n",
    "label = label_0 + label_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Conv2D(3, (3, 3), input_shape=input_shape, activation=\"relu\"),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        # Dropout(0.1),\n",
    "        Conv2D(3, (3, 3), activation=\"relu\"),\n",
    "        # MaxPooling2D((2, 2)),\n",
    "        # Dropout(0.1),\n",
    "        Flatten(),\n",
    "        # Dense(256, activation=\"relu\"),\n",
    "        # Dropout(0.2),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.1),\n",
    "        Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (240, 240, 3) # Thay đổi kích thước ảnh tùy thuộc vào dữ liệu của bạn\n",
    "model = create_model(input_shape)\n",
    "\n",
    "# Biên dịch mô hình\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/9\n",
      "7/7 [==============================] - 1s 72ms/step - loss: 2.5914 - accuracy: 0.4800\n",
      "Epoch 2/9\n",
      "7/7 [==============================] - 1s 76ms/step - loss: 0.9530 - accuracy: 0.5733\n",
      "Epoch 3/9\n",
      "7/7 [==============================] - 1s 71ms/step - loss: 0.6191 - accuracy: 0.6533\n",
      "Epoch 4/9\n",
      "7/7 [==============================] - 1s 75ms/step - loss: 0.6263 - accuracy: 0.6533\n",
      "Epoch 5/9\n",
      "7/7 [==============================] - 1s 74ms/step - loss: 0.5524 - accuracy: 0.7600\n",
      "Epoch 6/9\n",
      "7/7 [==============================] - 1s 75ms/step - loss: 0.4302 - accuracy: 0.8133\n",
      "Epoch 7/9\n",
      "7/7 [==============================] - 1s 74ms/step - loss: 0.4058 - accuracy: 0.8667\n",
      "Epoch 8/9\n",
      "7/7 [==============================] - 1s 76ms/step - loss: 0.3786 - accuracy: 0.8400\n",
      "Epoch 9/9\n",
      "7/7 [==============================] - 1s 75ms/step - loss: 0.2924 - accuracy: 0.9067\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2eda1fe8b50>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_img_array = np.array(lst_img)\n",
    "\n",
    "# Convert the list of labels to a NumPy array\n",
    "label_array = np.array(label)\n",
    "\n",
    "# Ensure label data is in the correct shape (matching the number of samples)\n",
    "label_array = label_array.reshape((-1, 1))\n",
    "\n",
    "# Assuming 'lst_img_array' is a list of images and 'label_array' is a list of corresponding labels (0 or 1)\n",
    "model.fit(lst_img_array, label_array, epochs=9, batch_size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"weight/classify2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 113ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.034799103"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(\"C:\\\\Users\\\\ADMIN\\\\OneDrive\\\\Desktop\\\\48shard_hat_workers850.jpg\")\n",
    "img = cv2.resize(img, (240, 240))\n",
    "img = img / 255.0\n",
    "img = np.expand_dims(img, axis=0)\n",
    "img = np.array(img)\n",
    "\n",
    "model.predict(img)[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM, LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_img_SVM = []\n",
    "\n",
    "for img in lst_img:\n",
    "    lst_img_SVM.append(img.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.78\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, ConfusionMatrixDisplay\n",
    "\n",
    "# Assuming lst_img_SVM and label are already defined\n",
    "# lst_img_SVM = ...  # Your input features\n",
    "# label = ...        # Your target labels\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(lst_img_SVM, label, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create an SVM classifier\n",
    "svm_classifier = SVC(kernel='linear', C=3, random_state=42)\n",
    "\n",
    "# Train the SVM classifier\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "\n",
    "# Visualize the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix for SVM Classifier')\n",
    "\n",
    "# Save the plot to a file\n",
    "plt.savefig('confusion_matrix.png')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.70\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(lst_img_SVM, label, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create a Logistic Regression classifier\n",
    "log_reg = LogisticRegression(random_state=42, max_iter=10000)\n",
    "\n",
    "# Train the Logistic Regression classifier\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Visualize the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=log_reg.classes_)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix for Logistic Regression')\n",
    "plt.savefig('confusion_matrix.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADD HOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import hog\n",
    "from skimage import color, exposure\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def extract_hog_features(image, visualize=False):\n",
    "    \"\"\"\n",
    "    Extract HOG features from an image.\n",
    "\n",
    "    Parameters:\n",
    "    - image: ndarray\n",
    "        Input image (grayscale or RGB).\n",
    "    - visualize: bool\n",
    "        If True, return the HOG image for visualization.\n",
    "\n",
    "    Returns:\n",
    "    - features: ndarray\n",
    "        HOG feature vector.\n",
    "    - hog_image: ndarray (optional)\n",
    "        HOG image for visualization if visualize is True.\n",
    "    \"\"\"\n",
    "    # Convert the image to grayscale if it is an RGB image\n",
    "    if len(image.shape) == 3:\n",
    "        image = color.rgb2gray(image)\n",
    "    \n",
    "    # Extract HOG features\n",
    "    if visualize:\n",
    "        features, hog_image = hog(image,\n",
    "                                  orientations=9,\n",
    "                                  pixels_per_cell=(8, 8),\n",
    "                                  cells_per_block=(2, 2),\n",
    "                                  block_norm='L2-Hys',\n",
    "                                  visualize=visualize,\n",
    "                                  transform_sqrt=True)\n",
    "        return features, hog_image\n",
    "    else:\n",
    "        features = hog(image,\n",
    "                       orientations=9,\n",
    "                       pixels_per_cell=(8, 8),\n",
    "                       cells_per_block=(2, 2),\n",
    "                       block_norm='L2-Hys',\n",
    "                       visualize=visualize,\n",
    "                       transform_sqrt=True)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_img_SVM = []\n",
    "\n",
    "for img in lst_img:\n",
    "    img = img/255.0\n",
    "    lst_img_SVM.append(extract_hog_features(image=img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.78\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(lst_img_SVM, label, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create an SVM classifier\n",
    "svm_classifier = SVC(kernel='linear',C=3, random_state=42)\n",
    "\n",
    "# Train the SVM classifier\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Visualize the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=svm_classifier.classes_)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix for SVM Classifier')\n",
    "plt.savefig('confusion_matrix.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['weight/svm_classifier2.pkl']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Assuming `svm_classifier` is your trained model\n",
    "joblib.dump(svm_classifier, 'weight/svm_classifier2.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "svm_classifier_loaded = joblib.load('weight/svm_classifier2.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_plot\\confusion_matrix.py:136: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig, ax = plt.subplots()\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(lst_img_SVM, label, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create a Logistic Regression classifier\n",
    "log_reg = LogisticRegression(random_state=42, max_iter=10000)\n",
    "\n",
    "# Train the Logistic Regression classifier\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Visualize the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=log_reg.classes_)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix for Logistic Regression')\n",
    "plt.savefig('confusion_matrix.png')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
