{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_0 = sorted(os.listdir(\"C:\\\\Users\\\\ADMIN\\\\Downloads\\\\helmet\\\\train\\\\0\"), key=lambda x: int(re.search(r'\\d+', x).group()))\n",
    "\n",
    "lst_1 = sorted(os.listdir(\"C:\\\\Users\\\\ADMIN\\\\Downloads\\\\helmet\\\\train\\\\1\"), key=lambda x: int(re.search(r'\\d+', x).group()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_img_0 = []\n",
    "\n",
    "common_size = (240, 240)  # Set the desired width and height\n",
    "\n",
    "for path in lst_0:\n",
    "    img_path = os.path.join(\"C:\\\\Users\\\\ADMIN\\\\Downloads\\\\helmet\\\\train\\\\0\", path)\n",
    "    img = cv2.imread(img_path)\n",
    "    resized_img = cv2.resize(img, common_size)\n",
    "    normalized_img = resized_img / 255.0\n",
    "    lst_img_0.append(normalized_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_img_1 = []\n",
    "\n",
    "common_size = (240, 240)  # Set the desired width and height\n",
    "\n",
    "for path in lst_1:\n",
    "    img_path = os.path.join(\"C:\\\\Users\\\\ADMIN\\\\Downloads\\\\helmet\\\\train\\\\1\", path)\n",
    "    img = cv2.imread(img_path)\n",
    "    resized_img = cv2.resize(img, common_size)\n",
    "    normalized_img = resized_img / 255.0\n",
    "    lst_img_1.append(normalized_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "label_0 = np.zeros(len(lst_0)).tolist()\n",
    "label_1 = np.ones(len(lst_1)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_img = lst_img_0 + lst_img_1\n",
    "label = label_0 + label_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Conv2D(3, (3, 3), input_shape=input_shape, activation=\"relu\"),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        # Dropout(0.1),\n",
    "        Conv2D(3, (3, 3), activation=\"relu\"),\n",
    "        # MaxPooling2D((2, 2)),\n",
    "        # Dropout(0.1),\n",
    "        Flatten(),\n",
    "        # Dense(256, activation=\"relu\"),\n",
    "        # Dropout(0.2),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.1),\n",
    "        Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (240, 240, 3) # Thay đổi kích thước ảnh tùy thuộc vào dữ liệu của bạn\n",
    "model = create_model(input_shape)\n",
    "\n",
    "# Biên dịch mô hình\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/9\n",
      "7/7 [==============================] - 1s 67ms/step - loss: 0.6384 - accuracy: 0.5000\n",
      "Epoch 2/9\n",
      "7/7 [==============================] - 0s 72ms/step - loss: 0.5091 - accuracy: 0.7564\n",
      "Epoch 3/9\n",
      "7/7 [==============================] - 1s 71ms/step - loss: 0.4395 - accuracy: 0.8590\n",
      "Epoch 4/9\n",
      "7/7 [==============================] - 0s 67ms/step - loss: 0.3584 - accuracy: 0.9103\n",
      "Epoch 5/9\n",
      "7/7 [==============================] - 1s 71ms/step - loss: 0.3025 - accuracy: 0.9103\n",
      "Epoch 6/9\n",
      "7/7 [==============================] - 1s 74ms/step - loss: 0.2761 - accuracy: 0.9231\n",
      "Epoch 7/9\n",
      "7/7 [==============================] - 1s 71ms/step - loss: 0.2105 - accuracy: 0.9744\n",
      "Epoch 8/9\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.1431 - accuracy: 0.9615\n",
      "Epoch 9/9\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.1589 - accuracy: 0.9231\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x260eb3c4090>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_img_array = np.array(lst_img)\n",
    "\n",
    "# Convert the list of labels to a NumPy array\n",
    "label_array = np.array(label)\n",
    "\n",
    "# Ensure label data is in the correct shape (matching the number of samples)\n",
    "label_array = label_array.reshape((-1, 1))\n",
    "\n",
    "# Assuming 'lst_img_array' is a list of images and 'label_array' is a list of corresponding labels (0 or 1)\n",
    "model.fit(lst_img_array, label_array, epochs=9, batch_size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"weight/classify.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import load_model\n",
    "\n",
    "# model = load_model(\"weight/classify.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.999195"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(\"D:\\\\Computer_Vision_(CS231)\\\\Analysis_traffic\\\\yolov9\\\\output_images1\\\\2.jpg\")\n",
    "img = cv2.resize(img, (240, 240))\n",
    "img = img / 255.0\n",
    "img = np.expand_dims(img, axis=0)\n",
    "img = np.array(img)\n",
    "\n",
    "model.predict(img)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"D:\\\\Computer_Vision_(CS231)\\\\Analysis_traffic\\\\yolov9\\\\imgs_after_preprocess\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_lst = []\n",
    "zero_lst = []\n",
    "files = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_path = sorted(os.listdir(folder_path), key=lambda x: int(re.search(r'\\d+', x).group()))\n",
    "\n",
    "for path in lst_path:\n",
    "    img_process_path = os.path.join(folder_path, path)\n",
    "    img = cv2.imread(img_process_path)\n",
    "    img = cv2.resize(img, (240, 240))\n",
    "    img = img / 255.0\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = np.array(img)\n",
    "\n",
    "    result = model.predict(img)\n",
    "    \n",
    "    print(result[0][0])\n",
    "\n",
    "    if result[0][0] >= 0.5:\n",
    "        one_lst.append(1)\n",
    "        # print(\"Length ones \" + str(len(one_lst)))\n",
    "    else:\n",
    "        zero_lst.append(0)\n",
    "        files.append(path)\n",
    "        # print(\"Length zeros \" + str(len(zero_lst)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(os.listdir(\"output_images\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
